# Observation and Testing in the Workflow

**How testing and observability are built into every stage of the prompt engineering workflow**

---

## Overview

The Integrated A/B Prompt Engineering System is designed with **testing and observability as first-class concerns**. Every workflow execution is:

- âœ… **Traceable** - Complete execution history with correlation IDs
- âœ… **Observable** - Real-time visibility into agent decisions
- âœ… **Testable** - Multiple test levels from unit to end-to-end
- âœ… **Debuggable** - Event sourcing enables time-travel debugging
- âœ… **Measurable** - Quality metrics and performance data

---

## Testing & Observation Integration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WORKFLOW EXECUTION WITH OBSERVATION POINTS                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User Request: "Create a prompt for meeting summarization"
    â”‚
    â”œâ”€â–º [OBSERVATION] Session ID assigned: session-abc-123
    â”œâ”€â–º [TRACE] Correlation ID: corr-456-def
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HOP 1: Context Discovery                                     â”‚
â”‚   â”œâ”€â–º [EVENT] TaskAnalyzed                                   â”‚
â”‚   â”œâ”€â–º [METRIC] Duration: 1200ms                              â”‚
â”‚   â”œâ”€â–º [TEST] âœ“ Required inputs identified                    â”‚
â”‚   â””â”€â–º [LOG] Found 2 required inputs, 1 context source        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HOP 2: Agent A Generation (Attempt 1)                        â”‚
â”‚   â”œâ”€â–º [EVENT] AttemptInitiated (attempt: 1)                  â”‚
â”‚   â”œâ”€â–º [EVENT] PromptGenerated                                â”‚
â”‚   â”œâ”€â–º [METRIC] Duration: 2000ms                              â”‚
â”‚   â”œâ”€â–º [TEST] âœ“ XML well-formed                               â”‚
â”‚   â”œâ”€â–º [TEST] âœ“ All required sections present                 â”‚
â”‚   â””â”€â–º [LOG] Generated 2450 characters                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HOP 3: Agent B Validation (Attempt 1)                        â”‚
â”‚   â”œâ”€â–º [EVENT] PromptValidated                                â”‚
â”‚   â”œâ”€â–º [METRIC] Duration: 1500ms, Score: 85/100               â”‚
â”‚   â”œâ”€â–º [TEST] âœ— Score below threshold (90)                    â”‚
â”‚   â”œâ”€â–º [VALIDATION] 12 checks run: 9 passed, 3 failed         â”‚
â”‚   â”œâ”€â–º [FEEDBACK] 3 items generated                           â”‚
â”‚   â””â”€â–º [LOG] Status: FAIL, retry needed                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â–º [OBSERVATION] Feedback loop triggered
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HOP 4: Feedback Loop (Agent B â†’ Agent A)                     â”‚
â”‚   â”œâ”€â–º [EVENT] FeedbackCycleStarted                           â”‚
â”‚   â”œâ”€â–º [EVENT] FeedbackApplied                                â”‚
â”‚   â”œâ”€â–º [METRIC] Duration: 2000ms                              â”‚
â”‚   â”œâ”€â–º [TEST] âœ“ Feedback addressed (3/3 items)                â”‚
â”‚   â””â”€â–º [LOG] Refinements applied                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HOP 5: Agent A Refinement (Attempt 2)                        â”‚
â”‚   â”œâ”€â–º [EVENT] AttemptInitiated (attempt: 2)                  â”‚
â”‚   â”œâ”€â–º [EVENT] PromptGenerated                                â”‚
â”‚   â”œâ”€â–º [METRIC] Duration: 2000ms                              â”‚
â”‚   â”œâ”€â–º [TEST] âœ“ Changes applied correctly                     â”‚
â”‚   â””â”€â–º [LOG] Generated 2850 characters (+400)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HOP 6: Agent B Re-Validation (Attempt 2)                     â”‚
â”‚   â”œâ”€â–º [EVENT] PromptValidated                                â”‚
â”‚   â”œâ”€â–º [EVENT] PromptApproved                                 â”‚
â”‚   â”œâ”€â–º [METRIC] Duration: 1500ms, Score: 95/100               â”‚
â”‚   â”œâ”€â–º [TEST] âœ“ Score above threshold                         â”‚
â”‚   â”œâ”€â–º [VALIDATION] 12 checks run: 12 passed, 0 failed        â”‚
â”‚   â””â”€â–º [LOG] Status: PASS                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: Files Saved                                          â”‚
â”‚   â”œâ”€â–º [EVENT] WorkflowSessionCompleted                       â”‚
â”‚   â”œâ”€â–º [METRIC] Total duration: 9000ms                        â”‚
â”‚   â”œâ”€â–º [TEST] âœ“ XML file created                              â”‚
â”‚   â”œâ”€â–º [TEST] âœ“ Report file created                           â”‚
â”‚   â””â”€â–º [ANALYTICS] Session stats recorded                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

COMPLETE OBSERVABILITY:
  â€¢ 13 Domain Events recorded
  â€¢ 6 Hops traced with correlation IDs
  â€¢ 12 Validation checks executed
  â€¢ 15+ Test assertions passed
  â€¢ Performance metrics captured at each stage
  â€¢ Full audit trail in event store
```

---

## Testing Levels

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Testing Pyramid                                                â”‚
â”‚                                                                 â”‚
â”‚                    â–²                                            â”‚
â”‚                   â•± â•²                                           â”‚
â”‚                  â•±   â•²        E2E Tests                         â”‚
â”‚                 â•±     â•²       (Workflow)                        â”‚
â”‚                â•±â”€â”€â”€â”€â”€â”€â”€â•²                                        â”‚
â”‚               â•±         â•²                                       â”‚
â”‚              â•±           â•²    Integration Tests                 â”‚
â”‚             â•±             â•²   (Agent A/B + Validation)          â”‚
â”‚            â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²                                    â”‚
â”‚           â•±                 â•²                                   â”‚
â”‚          â•±                   â•²  Unit Tests                      â”‚
â”‚         â•±                     â•² (Artifacts, Rules, Schemas)     â”‚
â”‚        â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. End-to-End Workflow Testing

### **Command: Test Complete Workflow**

```bash
# Run all test scenarios
make test-ab-workflow

# Test specific scenario
make xml-prompt-ab TASK="Create a prompt for meeting summarization"
```

### **What Gets Tested**

```
Test Workflow Execution:
â”‚
â”œâ”€ 1. Context Discovery
â”‚  â”œâ”€ âœ“ Identifies required inputs correctly
â”‚  â”œâ”€ âœ“ Identifies optional inputs
â”‚  â”œâ”€ âœ“ Maps context sources to Glean tools
â”‚  â””â”€ âœ“ Generates valid query templates
â”‚
â”œâ”€ 2. Agent A Generation
â”‚  â”œâ”€ âœ“ Produces well-formed XML
â”‚  â”œâ”€ âœ“ Includes all required sections
â”‚  â”œâ”€ âœ“ Uses correct prompt name format
â”‚  â”œâ”€ âœ“ Incorporates input analysis
â”‚  â””â”€ âœ“ Includes context requirements
â”‚
â”œâ”€ 3. Agent B Validation
â”‚  â”œâ”€ âœ“ Runs all validation checks
â”‚  â”œâ”€ âœ“ Calculates accurate scores
â”‚  â”œâ”€ âœ“ Generates actionable feedback (if needed)
â”‚  â””â”€ âœ“ Validates context specifications
â”‚
â”œâ”€ 4. Feedback Loop (if score < 90)
â”‚  â”œâ”€ âœ“ Feedback reaches Agent A
â”‚  â”œâ”€ âœ“ Agent A addresses feedback items
â”‚  â”œâ”€ âœ“ XML evolves correctly
â”‚  â””â”€ âœ“ Retry logic works (max 3 attempts)
â”‚
â””â”€ 5. Output Generation
   â”œâ”€ âœ“ XML file created
   â”œâ”€ âœ“ Report file created
   â”œâ”€ âœ“ Files are valid
   â””â”€ âœ“ Session completes successfully
```

### **Test Output Example**

```bash
$ make test-ab-workflow

Running test scenarios...

[1/3] Testing: Meeting Summarization
  âœ“ Context discovery identified 2 required inputs
  âœ“ Context discovery identified 1 context source
  âœ“ Agent A generated valid XML (attempt 1)
  âœ“ Agent B validation score: 100/100
  âœ“ No feedback loop needed (first attempt success)
  âœ“ Output files created
  Duration: 2.3s
  Status: PASS âœ“

[2/3] Testing: Code Review
  âœ“ Context discovery identified 2 required inputs
  âœ“ Context discovery identified 2 context sources
  âœ“ Agent A generated valid XML (attempt 1)
  âœ“ Agent B validation score: 100/100
  âœ“ No feedback loop needed (first attempt success)
  âœ“ Output files created
  Duration: 2.1s
  Status: PASS âœ“

[3/3] Testing: Customer Feedback Analysis
  âœ“ Context discovery identified 1 required input
  âœ“ Context discovery identified 2 context sources
  âœ“ Agent A generated valid XML (attempt 1)
  âœ“ Agent B validation score: 100/100
  âœ“ No feedback loop needed (first attempt success)
  âœ“ Output files created
  Duration: 2.5s
  Status: PASS âœ“

========================================
All tests passed! (3/3)
Total duration: 6.9s
========================================
```

---

## 2. Observability Features

### **2.1 Execution Trace with Correlation IDs**

Every workflow execution is fully traceable:

```json
{
  "session_id": "session-abc-123-xyz",
  "correlation_id": "corr-456-def-ghi",
  "trace": [
    {
      "hop": 1,
      "timestamp": "2026-01-26T14:30:01.000Z",
      "from": "START",
      "to": "ContextDiscoveryNode",
      "duration_ms": 1200,
      "payload_type": "UserRequest",
      "result_type": "InputAnalysis",
      "status": "success"
    },
    {
      "hop": 2,
      "timestamp": "2026-01-26T14:30:03.000Z",
      "from": "ContextDiscoveryNode",
      "to": "AgentANode",
      "duration_ms": 2000,
      "payload_type": "GenerationRequest",
      "result_type": "PromptSpecification",
      "status": "success"
    },
    {
      "hop": 3,
      "timestamp": "2026-01-26T14:30:05.500Z",
      "from": "AgentANode",
      "to": "AgentBNode",
      "duration_ms": 1500,
      "payload_type": "ValidationRequest",
      "result_type": "ValidationResult",
      "status": "success",
      "score": 85,
      "isValid": false
    },
    {
      "hop": 4,
      "timestamp": "2026-01-26T14:30:07.000Z",
      "from": "AgentBNode",
      "to": "AgentANode",
      "duration_ms": 2000,
      "payload_type": "RefinementRequest",
      "result_type": "PromptSpecification",
      "status": "success",
      "note": "FEEDBACK_LOOP"
    },
    {
      "hop": 5,
      "timestamp": "2026-01-26T14:30:09.500Z",
      "from": "AgentANode",
      "to": "AgentBNode",
      "duration_ms": 1500,
      "payload_type": "ValidationRequest",
      "result_type": "ValidationResult",
      "status": "success",
      "score": 95,
      "isValid": true
    },
    {
      "hop": 6,
      "timestamp": "2026-01-26T14:30:10.000Z",
      "from": "AgentBNode",
      "to": "OutputNode",
      "duration_ms": 500,
      "payload_type": "SaveRequest",
      "result_type": "FilesCreated",
      "status": "success"
    }
  ],
  "total_hops": 6,
  "total_duration_ms": 9000,
  "attempts": 2,
  "final_status": "SUCCESS"
}
```

**Observability Benefits**:
- âœ… Track execution flow through all hops
- âœ… Identify performance bottlenecks
- âœ… Debug failures at specific hop
- âœ… Correlate events across distributed system

---

### **2.2 Real-Time Workflow Monitoring**

During execution, you can observe:

```bash
$ make xml-prompt-ab TASK="Create a prompt for meeting summarization"

[14:30:01] â†’ Starting workflow session: session-abc-123
[14:30:01] â†’ HOP 1: Context Discovery
           Analyzing task: "Create a prompt for meeting summarization"

[14:30:02] âœ“ Context Discovery Complete
           Required inputs: 2 (meeting_transcript, attendee_list)
           Context sources: 1 (previous_meetings)
           Glean tools: mcp__glean__meeting_lookup

[14:30:03] â†’ HOP 2: Agent A Generation (Attempt 1)
           Generating XML prompt with context analysis...

[14:30:05] âœ“ Generation Complete
           Prompt name: m3t-4ng-s1m
           XML size: 2,450 characters
           Sections: 8/8 required

[14:30:05] â†’ HOP 3: Agent B Validation (Attempt 1)
           Running validation checks...

[14:30:07] âš  Validation: Score 85/100 (threshold: 90)
           Status: FAIL
           Feedback items: 3
           - Add at least one more good example
           - Add validation rules for all required inputs
           - Improve specificity in instructions

[14:30:07] â†’ HOP 4: Feedback Loop Initiated
           Sending feedback to Agent A...

[14:30:07] â†’ HOP 5: Agent A Refinement (Attempt 2)
           Addressing feedback items...

[14:30:09] âœ“ Refinement Complete
           Changes applied: 3/3 feedback items
           - Added 2nd good example âœ“
           - Added detailed validation rules âœ“
           - Enhanced instruction specificity âœ“

[14:30:09] â†’ HOP 6: Agent B Re-Validation (Attempt 2)
           Running validation checks...

[14:30:11] âœ“ Validation: Score 95/100
           Status: PASS
           All checks passed!

[14:30:11] â†’ Saving output files...
[14:30:11] âœ“ Files saved:
           - output/ab-prompt.xml
           - output/ab-prompt-ab-report.json

[14:30:11] âœ“ Session completed successfully!

Summary:
- Session ID: session-abc-123
- Final Score: 95/100
- Attempts: 2
- Duration: 9.0 seconds
- Hops: 6
```

---

### **2.3 Event Sourcing for Time-Travel Debugging**

All domain events are recorded:

```
Event Stream: session-abc-123
â”‚
â”œâ”€ [1] WorkflowSessionStarted
â”‚      timestamp: 2026-01-26T14:30:01.000Z
â”‚      user_request: "Create a prompt for meeting summarization"
â”‚
â”œâ”€ [2] TaskAnalyzed
â”‚      required_inputs: ["meeting_transcript", "attendee_list"]
â”‚      context_sources: ["previous_meetings"]
â”‚
â”œâ”€ [3] AttemptInitiated
â”‚      attempt_number: 1
â”‚
â”œâ”€ [4] PromptGenerated
â”‚      prompt_name: "m3t-4ng-s1m"
â”‚      xml_size: 2450
â”‚      generation_metadata: {...}
â”‚
â”œâ”€ [5] PromptValidated
â”‚      quality_score: 85
â”‚      is_valid: false
â”‚      checks_passed: 9/12
â”‚
â”œâ”€ [6] FeedbackGenerated
â”‚      feedback_items: [
â”‚        "Add at least one more good example",
â”‚        "Add validation rules for all required inputs",
â”‚        "Improve specificity in instructions"
â”‚      ]
â”‚
â”œâ”€ [7] FeedbackCycleStarted
â”‚      cycle_number: 1
â”‚
â”œâ”€ [8] FeedbackApplied
â”‚      refinements: ["Added 2nd good example", ...]
â”‚
â”œâ”€ [9] AttemptInitiated
â”‚      attempt_number: 2
â”‚
â”œâ”€ [10] PromptGenerated
â”‚       prompt_name: "m3t-4ng-s1m"
â”‚       xml_size: 2850
â”‚       changes_from_previous: [...]
â”‚
â”œâ”€ [11] PromptValidated
â”‚       quality_score: 95
â”‚       is_valid: true
â”‚       checks_passed: 12/12
â”‚
â”œâ”€ [12] PromptApproved
â”‚       approval_reason: "Score >= 90 AND no errors"
â”‚
â””â”€ [13] WorkflowSessionCompleted
       final_score: 95
       total_attempts: 2
       duration_ms: 9000
```

**Debug Capabilities**:
- âœ… **Replay workflow** from any point
- âœ… **Inspect state** at each event
- âœ… **Compare attempts** to see what changed
- âœ… **Audit trail** for compliance

**Example: Time-Travel Query**

```typescript
// Get workflow state at specific point in time
const stateAfterFirstAttempt = reconstructAggregate(
  "session-abc-123",
  upToEvent: 5  // After PromptValidated (attempt 1)
);

console.log(stateAfterFirstAttempt.currentPrompt.xmlContent);
console.log(stateAfterFirstAttempt.validationResult.qualityScore); // 85

// Compare with final state
const finalState = reconstructAggregate("session-abc-123");
console.log(finalState.validationResult.qualityScore); // 95

// See exact changes
const diff = compareXML(
  stateAfterFirstAttempt.currentPrompt.xmlContent,
  finalState.currentPrompt.xmlContent
);
```

---

### **2.4 Validation Report Analytics**

Every validation produces detailed metrics:

```json
{
  "validation_id": "val-789-jkl",
  "timestamp": "2026-01-26T14:30:09.500Z",
  "attempt_number": 2,

  "overall_result": {
    "is_valid": true,
    "quality_score": 95,
    "pass_threshold": 90
  },

  "score_breakdown": {
    "structural": {
      "score": 35,
      "max": 35,
      "percentage": 100,
      "checks": {
        "xml_well_formed": {"status": "pass", "points": 10},
        "required_sections_present": {"status": "pass", "points": 15},
        "tag_hierarchy": {"status": "pass", "points": 10},
        "naming_convention": {"status": "pass", "points": 5}
      }
    },
    "completeness": {
      "score": 30,
      "max": 30,
      "percentage": 100,
      "checks": {
        "section_content": {"status": "pass", "points": 15},
        "examples_quality": {"status": "pass", "points": 10},
        "instructions_structure": {"status": "pass", "points": 5}
      }
    },
    "quality": {
      "score": 25,
      "max": 25,
      "percentage": 100,
      "checks": {
        "clarity_and_specificity": {"status": "pass", "points": 10},
        "examples_effectiveness": {"status": "pass", "points": 10},
        "constraints_and_validation": {"status": "pass", "points": 5}
      }
    },
    "context_quality": {
      "score": 10,
      "max": 10,
      "percentage": 100,
      "checks": {
        "required_inputs_defined": {"status": "pass", "points": 3},
        "input_descriptions_clear": {"status": "pass", "points": 2},
        "glean_queries_valid": {"status": "pass", "points": 3},
        "context_sources_accessible": {"status": "pass", "points": 2}
      }
    }
  },

  "checks_summary": {
    "total": 12,
    "passed": 12,
    "failed": 0,
    "warnings": 0
  },

  "performance_metrics": {
    "validation_duration_ms": 1500,
    "xml_parse_time_ms": 50,
    "checks_execution_time_ms": 1200,
    "feedback_generation_time_ms": 250
  },

  "comparison_to_previous": {
    "score_delta": +10,
    "new_issues": 0,
    "resolved_issues": 3,
    "improvements": [
      "Added 2nd good example",
      "Added detailed validation rules",
      "Enhanced instruction specificity"
    ]
  }
}
```

**Analytics Use Cases**:
- ğŸ“Š Track quality trends over time
- ğŸ“ˆ Identify common failure patterns
- ğŸ¯ Optimize validation rules
- ğŸ” Debug specific check failures

---

## 3. Testing Validation Rules

### **Test New Validation Rules**

Before deploying new rules, test them:

```bash
# Create test validation rules
cp validation-rules.json validation-rules-test.json

# Edit validation-rules-test.json
# - Change threshold: 90 â†’ 95
# - Add new check: "domain_knowledge_present"
# - Update points: examples_quality: 10 â†’ 15

# Test with new rules
make xml-prompt-ab \
  TASK="Create a prompt for meeting summarization" \
  VALIDATION_RULES=validation-rules-test.json

# Compare results
diff output/ab-prompt-ab-report.json output/ab-prompt-ab-report-test.json
```

**Validation Rule Testing Checklist**:
- âœ… Does the new rule improve quality?
- âœ… Does it cause false positives?
- âœ… Is the scoring fair?
- âœ… Can agents address the feedback?
- âœ… Does it align with organization standards?

---

## 4. Testing Examples

### **Test Example Quality**

Validate that examples meet standards:

```bash
# Validate a good example
make validate-prompt FILE="workflow-orchestration/global/examples/good/well-structured-prompts/example-001-meeting-summary.xml"

Expected output:
âœ“ Score: 95-100/100
âœ“ Status: PASS
âœ“ All checks passed

# Validate a bad example (should fail)
make validate-prompt FILE="workflow-orchestration/global/examples/bad/anti-patterns/example-001-flat-structure.xml"

Expected output:
âœ— Score: 40-60/100
âœ— Status: FAIL
âœ— Issues identified: [list of problems]
```

### **Add New Examples with Testing**

```bash
# 1. Create new example
vim workflow-orchestration/global/examples/good/my-new-example.xml

# 2. Test it validates correctly
make validate-prompt FILE="workflow-orchestration/global/examples/good/my-new-example.xml"

# 3. Update metadata
vim workflow-orchestration/global/examples/good/_metadata.json

# 4. Test discovery
make list-examples

# 5. Test agent can use it
make xml-prompt-ab TASK="Similar to my new example"
```

---

## 5. Agent Testing

### **5.1 Test Agent A (Generator)**

```bash
# Test generation without validation
make test-agent-a TASK="Create a prompt for meeting summarization"

# Checks:
# âœ“ XML is well-formed
# âœ“ All required sections present
# âœ“ Context analysis performed
# âœ“ Input specifications generated
```

### **5.2 Test Agent B (Validator)**

```bash
# Test validation with known good prompt
make test-agent-b FILE="examples/good/example-001.xml"

# Expected: Score 95-100, PASS

# Test validation with known bad prompt
make test-agent-b FILE="examples/bad/example-001.xml"

# Expected: Score <90, FAIL with specific feedback
```

### **5.3 Test Feedback Loop**

```bash
# Test that feedback improves quality
make test-feedback-loop TASK="Create a prompt for meeting summarization"

# Monitors:
# âœ“ Attempt 1: Score < 90
# âœ“ Feedback generated with specific items
# âœ“ Attempt 2: Score >= 90
# âœ“ Feedback items addressed
# âœ“ XML evolved correctly
```

---

## 6. Integration Testing

### **Test Glean MCP Integration**

```bash
# Test that Glean tools are correctly identified
make test-glean-integration TASK="Create a prompt for meeting summarization"

# Checks:
# âœ“ Correct Glean tools identified (mcp__glean__meeting_lookup)
# âœ“ Query templates generated
# âœ“ Context sources mapped
```

### **Test Event Store**

```bash
# Test event persistence
make test-event-store

# Checks:
# âœ“ Events written correctly
# âœ“ Events retrievable by session ID
# âœ“ Event ordering preserved
# âœ“ Aggregate reconstruction works
```

---

## 7. Performance Testing

### **Measure Workflow Performance**

```bash
# Run performance benchmark
make benchmark

Output:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scenario                    â”‚ Avg (ms) â”‚ Min (ms) â”‚ Max (ms) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Context Discovery           â”‚ 1,200    â”‚ 1,000    â”‚ 1,500    â”‚
â”‚ Agent A Generation (1st)    â”‚ 2,000    â”‚ 1,800    â”‚ 2,500    â”‚
â”‚ Agent B Validation          â”‚ 1,500    â”‚ 1,200    â”‚ 2,000    â”‚
â”‚ Agent A Refinement (2nd)    â”‚ 2,000    â”‚ 1,800    â”‚ 2,500    â”‚
â”‚ Agent B Re-validation       â”‚ 1,500    â”‚ 1,200    â”‚ 2,000    â”‚
â”‚ File Output                 â”‚ 500      â”‚ 300      â”‚ 800      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total (1 attempt)           â”‚ 5,200    â”‚ 4,500    â”‚ 6,500    â”‚
â”‚ Total (2 attempts)          â”‚ 9,000    â”‚ 8,000    â”‚ 11,000   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ“ All scenarios within acceptable latency
âœ“ P95: 10.5 seconds
âœ“ P99: 12.0 seconds
```

---

## 8. Debugging Workflows

### **Debug Failed Workflow**

```bash
# Run with verbose logging
make xml-prompt-ab TASK="..." DEBUG=true

# Output shows:
# - Full event stream
# - Agent request/response payloads
# - Validation check details
# - Error stack traces

# Inspect specific session
make inspect-session SESSION_ID=session-abc-123

# Shows:
# - All events in order
# - Full execution trace
# - State at each hop
# - Performance metrics
```

### **Common Debugging Scenarios**

**Scenario 1: Low Quality Score**
```bash
# 1. Check validation report
cat output/ab-prompt-ab-report.json | jq '.scoreBreakdown'

# 2. Identify failing checks
cat output/ab-prompt-ab-report.json | jq '.checks[] | select(.status == "fail")'

# 3. Review feedback
cat output/ab-prompt-ab-report.json | jq '.feedback'

# 4. Compare to good examples
diff output/ab-prompt.xml workflow-orchestration/global/examples/good/example-001.xml
```

**Scenario 2: Infinite Loop (Max Attempts)**
```bash
# Check if feedback is being addressed
make inspect-session SESSION_ID=session-abc-123 | grep "FeedbackApplied"

# Review XML evolution
make compare-attempts SESSION_ID=session-abc-123

# Shows side-by-side diff of attempts
```

**Scenario 3: Wrong Context Identified**
```bash
# Debug context discovery
make debug-context TASK="..."

# Shows:
# - Pattern matching results
# - Input detection logic
# - Context source selection
# - Glean tool mapping
```

---

## 9. Continuous Testing

### **Pre-Commit Hooks**

```bash
#!/bin/bash
# .git/hooks/pre-commit

# Run validation rule tests
make test-validation-rules || exit 1

# Test all examples still validate
make test-all-examples || exit 1

# Run quick workflow test
make test-ab-workflow-quick || exit 1

echo "âœ“ All pre-commit tests passed"
```

### **CI/CD Pipeline**

```yaml
# .github/workflows/test.yml
name: Test Workflow

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - name: Install dependencies
        run: npm install

      - name: Test validation rules
        run: make test-validation-rules

      - name: Test examples
        run: make test-all-examples

      - name: Test workflows
        run: make test-ab-workflow

      - name: Performance benchmark
        run: make benchmark

      - name: Upload reports
        uses: actions/upload-artifact@v2
        with:
          name: test-reports
          path: output/*.json
```

---

## 10. Monitoring in Production

### **Metrics to Track**

```javascript
// Prometheus metrics
workflow_executions_total{status="success"}
workflow_executions_total{status="failure"}
workflow_duration_seconds{percentile="p95"}
workflow_attempts_count{attempt="1"}
workflow_attempts_count{attempt="2"}
workflow_attempts_count{attempt="3"}
validation_score_average
validation_checks_failed_total{check="examples_quality"}
feedback_loop_triggered_total
```

### **Alerting Rules**

```yaml
# alerting-rules.yml
groups:
  - name: workflow_quality
    rules:
      - alert: HighFailureRate
        expr: rate(workflow_executions_total{status="failure"}[5m]) > 0.1
        for: 5m
        annotations:
          summary: "Workflow failure rate above 10%"

      - alert: LowQualityScores
        expr: validation_score_average < 85
        for: 10m
        annotations:
          summary: "Average validation score below 85"

      - alert: SlowWorkflows
        expr: workflow_duration_seconds{percentile="p95"} > 15
        for: 5m
        annotations:
          summary: "P95 latency above 15 seconds"
```

---

## Summary

### Testing Coverage

| Test Level | What's Tested | How Often |
|------------|---------------|-----------|
| **Unit Tests** | Validation rules, schemas, artifacts | Every commit |
| **Integration Tests** | Agent A/B, validation, context discovery | Every commit |
| **E2E Tests** | Complete workflow scenarios | Every commit |
| **Performance Tests** | Latency, throughput | Daily |
| **Regression Tests** | Known good/bad examples | Every commit |

### Observability Features

| Feature | Benefit | Implementation |
|---------|---------|----------------|
| **Correlation IDs** | Trace requests across hops | Event metadata |
| **Event Sourcing** | Complete audit trail | Event store |
| **Validation Reports** | Quality insights | JSON reports |
| **Execution Trace** | Debug failures | Hop logging |
| **Performance Metrics** | Optimize latency | Prometheus |

### Key Insights

âœ… **Everything is Observable** - Every hop, every decision, every validation check is logged and traceable

âœ… **Everything is Testable** - From individual validation rules to complete workflows

âœ… **Everything is Debuggable** - Event sourcing enables time-travel debugging

âœ… **Everything is Measurable** - Quality scores, performance metrics, success rates

**Result**: A system that's not just production-ready, but production-observable and production-testable.

---

**Last Updated:** 2026-01-26
**Version:** 1.0.0
**Status:** âœ… Production Ready
